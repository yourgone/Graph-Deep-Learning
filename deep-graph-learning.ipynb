{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T19:04:07.090633Z","iopub.execute_input":"2021-07-16T19:04:07.090971Z","iopub.status.idle":"2021-07-16T19:04:07.100298Z","shell.execute_reply.started":"2021-07-16T19:04:07.090943Z","shell.execute_reply":"2021-07-16T19:04:07.099492Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/google-quest-challenge/sample_submission.csv\n/kaggle/input/google-quest-challenge/train.csv\n/kaggle/input/google-quest-challenge/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Deep Graph Embeddings \n\nThis is a notebook which walks through 2 of the most popular deep learning based graph embeddings - SDNE and LINE. These architectures are different from the previous notebooks owing to the fact that these use first and second order proximity to determine the node representations. The first order proximity suggests that nodes can be related based on adjacency and the second order suggests that nodes are characterised based on the neighbourhood of the nodes.Both the papers associated with the embeddings are present here:\n\n- [SDNE](https://paperswithcode.com/method/sdne)\n- [LINE](https://paperswithcode.com/method/line)\n\nThese are very high order embeddings and used for capturing representations on exclusively large networks. These are scalable representations which are based on regressed adjacency properties and laplacian maps.\n\n<img src=\"https://pbs.twimg.com/media/DPJSagrX0AAYdSy.jpg\">","metadata":{}},{"cell_type":"code","source":"!pip install networkx\n!pip install gensim\n!pip install torch\n!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2021-07-11T11:28:26.625956Z","iopub.execute_input":"2021-07-11T11:28:26.626336Z","iopub.status.idle":"2021-07-11T11:28:50.426814Z","shell.execute_reply.started":"2021-07-11T11:28:26.626304Z","shell.execute_reply":"2021-07-11T11:28:50.425799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SDNE (Structural Deep Network Embeddings)\n\n<img src=\"https://www.programmersought.com/images/979/223a8a8bc9b82f9255018d248c355c8b.png\">\n\n### SDNE algorithm principle\n\n#### Similarity definition\n\nThe definition of similarity in SDNE is the same as LINE. Simply put, the first-order similarity measures the similarity between two adjacent vertex pairs. The second-order similarity measures the similarity of the neighbor sets of two vertices.\n\n#### 2nd order similarity optimization goal\n\n``` L2nd​=∑i=1n​∣∣x^i​−xi​∣∣22​```\n\nHere we use the adjacency matrix of the graph for input. For the i-th vertex, we have x_i=s_i xi​=si​,Every s_i si​Both contain the neighbor structure information of vertex i, so this reconstruction process can make vertices with similar structures have similar embedding representation vectors.\n\nOne problem here is that due to the sparseness of the graph, the number of non-zero elements in the adjacency matrix S is far fewer than zero elements, so for the neural network as long as all output 0 can achieve a good effect, this is not ours want.\n\nOne method given in the article is to use a weighted loss function, which has a higher penalty coefficient for non-zero elements.\n\n1st order similarity optimization goal\nCapture Reconstruction loss of the predicted and true values\n\n2nd order similarity optimization goal\nUse the trace of the laplacian matrix and normalize the results\n\nThe loss function can make the embedding vectors corresponding to two adjacent vertices in the graph close in the hidden space.\n\n\nWhere L is the Laplacian matrix corresponding to the graph, L = D-S L=D−S, D is the degree matrix of the vertices in the graph, and S is the adjacency matrix.\n\n\nOverall optimization goal\nThe loss function of joint optimization is\n```Lmix​=L2nd​+αL1st​+νLreg​```\n\nL_{reg} Lreg​Is the regularization term, \nalpha αTo control the parameters of the first-order loss\n\n\nThe second order proximity is preserved by passing the adjacency matrix of te graph through an unsupervised autoencoder which has a built in reconstruction loss function it must minimize.\n\n<img src=\"https://miro.medium.com/proxy/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png\">","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv('../input/google-quest-challenge/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T19:04:15.420573Z","iopub.execute_input":"2021-07-16T19:04:15.420882Z","iopub.status.idle":"2021-07-16T19:04:15.762443Z","shell.execute_reply.started":"2021-07-16T19:04:15.420853Z","shell.execute_reply":"2021-07-16T19:04:15.761485Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   qa_id                                     question_title  \\\n0      0  What am I losing when using extension tubes in...   \n1      1  What is the distinction between a city and a s...   \n2      2  Maximum protusion length for through-hole comp...   \n3      3              Can an affidavit be used in Beit Din?   \n4      5       How do you make a binary image in Photoshop?   \n\n                                       question_body question_user_name  \\\n0  After playing around with macro photography on...               ysap   \n1  I am trying to understand what kinds of places...      russellpierce   \n2  I'm working on a PCB that has through-hole com...          Joe Baker   \n3  An affidavit, from what i understand, is basic...         Scimonster   \n4  I am trying to make a binary image. I want mor...            leigero   \n\n                                  question_user_page  \\\n0         https://photo.stackexchange.com/users/1024   \n1           https://rpg.stackexchange.com/users/8774   \n2  https://electronics.stackexchange.com/users/10157   \n3       https://judaism.stackexchange.com/users/5151   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                              answer answer_user_name  \\\n0  I just got extension tubes, so here's the skin...           rfusca   \n1  It might be helpful to look into the definitio...     Erik Schmidt   \n2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n\n                                    answer_user_page  \\\n0         https://photo.stackexchange.com/users/1917   \n1           https://rpg.stackexchange.com/users/1871   \n2  https://electronics.stackexchange.com/users/64754   \n3       https://judaism.stackexchange.com/users/4794   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                                 url   category  ...  \\\n0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n\n  question_well_written  answer_helpful  answer_level_of_information  \\\n0              1.000000        1.000000                     0.666667   \n1              0.888889        0.888889                     0.555556   \n2              0.777778        0.777778                     0.555556   \n3              0.888889        0.833333                     0.333333   \n4              1.000000        1.000000                     0.666667   \n\n   answer_plausible  answer_relevance  answer_satisfaction  \\\n0          1.000000          1.000000             0.800000   \n1          0.888889          0.888889             0.666667   \n2          1.000000          1.000000             0.666667   \n3          0.833333          1.000000             0.800000   \n4          1.000000          1.000000             0.800000   \n\n   answer_type_instructions  answer_type_procedure  \\\n0                       1.0               0.000000   \n1                       0.0               0.000000   \n2                       0.0               0.333333   \n3                       0.0               0.000000   \n4                       1.0               0.000000   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.000000             1.000000  \n1                        0.666667             0.888889  \n2                        1.000000             0.888889  \n3                        1.000000             1.000000  \n4                        1.000000             1.000000  \n\n[5 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qa_id</th>\n      <th>question_title</th>\n      <th>question_body</th>\n      <th>question_user_name</th>\n      <th>question_user_page</th>\n      <th>answer</th>\n      <th>answer_user_name</th>\n      <th>answer_user_page</th>\n      <th>url</th>\n      <th>category</th>\n      <th>...</th>\n      <th>question_well_written</th>\n      <th>answer_helpful</th>\n      <th>answer_level_of_information</th>\n      <th>answer_plausible</th>\n      <th>answer_relevance</th>\n      <th>answer_satisfaction</th>\n      <th>answer_type_instructions</th>\n      <th>answer_type_procedure</th>\n      <th>answer_type_reason_explanation</th>\n      <th>answer_well_written</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>What am I losing when using extension tubes in...</td>\n      <td>After playing around with macro photography on...</td>\n      <